---
title: "Clinical Decision Making and Pattern Recognition in Health Care"
author: "Avery Holloman"
date: "2024-08-20"
output: html_document
---

```{r}
# First I utlized the "readxl" package to read in my Excel file that I converted to ".xlsx" from common delimited format to handle the data better
library(readxl)
# Second, I utilized the dplyr because it is part of a family of functional tools in the Tidyverse that allows myself to filter, arrange, summarize, and manipulate the data frame as I am going through my statistical analysis.
library(dplyr)
# Thirdly, I made revisines to my code multiple times as I was receiving syntax erros in the data so I researched the "anomalize" package for better utilization of the anomaly detection for my time series data becuase it helped identify outliers in my time series data by decomposing specific features within my data to normalize the points for better anomaly detection method attributes for data visualization. 
library(anomalize)
#tibbletime extends the tibble data structure to better handle time series data. It enables time-based manipulation of tibbles, making it easier to work with date and time indexes.
library(tibbletime)
library(ggplot2)

# Load your data from the Excel file
healthcare <- read_excel("C:/Users/jacob/OneDrive/Desktop/R Studio Projects 2024/Datasets/healthcare.xlsx")

# Add a Date column assuming the data represents monthly records starting from January 2020
healthcare <- healthcare %>% 
  mutate(Date = seq(as.Date("2020-01-01"), by = "month", length.out = n()))

# Convert the data to a tibble
healthcare_tbl <- as_tibble(healthcare)

# Convert to a time-based tibble
healthcare_time_tbl <- healthcare_tbl %>%
  as_tbl_time(index = Date)

# Perform anomaly detection on the 'Blood_Pressure_mmHg' column
anomaly_detection <- healthcare_time_tbl %>%
  time_decompose(Blood_Pressure_mmHg, method = "stl") %>%
  anomalize(remainder, method = "iqr") %>%
  time_recompose()

# Plot the anomalies
plot_anomalies(anomaly_detection)

```

```{r}
# Load necessary libraries
library(readxl)
library(cluster)
library(ggplot2)

# Load your data from the Excel file
healthcare <- read_excel("C:/Users/jacob/OneDrive/Desktop/R Studio Projects 2024/Datasets/healthcare.xlsx")

# Perform K-means clustering based on 'Blood_Pressure_mmHg' and 'Cholesterol_mg_dL'
set.seed(123)
kmeans_result <- kmeans(healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], centers = 5)

# Plot K-means result
ggplot(healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = as.factor(kmeans_result$cluster))) +
  geom_point(size = 1.0) +
  geom_point(data = as.data.frame(kmeans_result$centers), aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL), color = "black", size = 5, shape = 4) +
  ggtitle("K-means - 5 Prototypes per Class")

```



```{r}
# Load necessary libraries
library(readxl)
library(cluster)
library(ggplot2)
library(MASS) # For Bayes decision boundary


# K-means clustering based on 'Blood_Pressure_mmHg' and 'Cholesterol_mg_dL'
set.seed(123)
kmeans_result <- kmeans(healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], centers = 5)

# Create a grid of points spanning the feature space
x_min <- min(healthcare$Blood_Pressure_mmHg) - 10
x_max <- max(healthcare$Blood_Pressure_mmHg) + 10
y_min <- min(healthcare$Cholesterol_mg_dL) - 10
y_max <- max(healthcare$Cholesterol_mg_dL) + 10

grid <- expand.grid(Blood_Pressure_mmHg = seq(x_min, x_max, length.out = 100),
                    Cholesterol_mg_dL = seq(y_min, y_max, length.out = 100))

# Function to assign each point in the grid to the nearest cluster center
assign_cluster <- function(x, centers) {
  distances <- apply(centers, 1, function(center) sqrt(sum((x - center)^2)))
  return(which.min(distances))
}

# Assign each grid point to the nearest cluster
grid$cluster <- apply(grid, 1, assign_cluster, centers = kmeans_result$centers)
grid$cluster <- as.factor(grid$cluster)

# Estimate the Bayes decision boundary using linear discriminant analysis
lda_model <- lda(cluster ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = data.frame(healthcare, cluster = kmeans_result$cluster))
grid$decision_boundary <- predict(lda_model, grid)$class

# Plot K-means result with decision boundary
ggplot(healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = as.factor(kmeans_result$cluster))) +
  geom_point(size = 3) +
  geom_point(data = as.data.frame(kmeans_result$centers), aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL), color = "black", size = 5, shape = 4) +
  geom_contour(data = grid, aes(z = as.numeric(decision_boundary)), bins = 5, color = "blue", linetype = "dashed") +
  ggtitle("K-means Clustering with Bayes Decision Boundary") +
  scale_color_discrete(name = "Cluster")
```
```{r}
# Load necessary libraries
library(readxl)
library(cluster)
library(ggplot2)
library(MASS) # For Bayes decision boundary

# K-means clustering based on 'Blood_Pressure_mmHg' and 'Cholesterol_mg_dL'
set.seed(123)
kmeans_result <- kmeans(healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], centers = 5)

# Create a grid of points spanning the feature space
x_min <- min(healthcare$Blood_Pressure_mmHg) - 10
x_max <- max(healthcare$Blood_Pressure_mmHg) + 10
y_min <- min(healthcare$Cholesterol_mg_dL) - 10
y_max <- max(healthcare$Cholesterol_mg_dL) + 10

grid <- expand.grid(Blood_Pressure_mmHg = seq(x_min, x_max, length.out = 100),
                    Cholesterol_mg_dL = seq(y_min, y_max, length.out = 100))

# Function to assign each point in the grid to the nearest cluster center
assign_cluster <- function(x, centers) {
  distances <- apply(centers, 1, function(center) sqrt(sum((x - center)^2)))
  return(which.min(distances))
}

# Assign each grid point to the nearest cluster
grid$cluster <- apply(grid, 1, assign_cluster, centers = kmeans_result$centers)
grid$cluster <- as.factor(grid$cluster)

# Estimate the Bayes decision boundary using linear discriminant analysis
lda_model <- lda(cluster ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = data.frame(healthcare, cluster = kmeans_result$cluster))
grid$decision_boundary <- predict(lda_model, grid)$class

# Plot K-means result with decision boundary and smaller data points
ggplot(healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = as.factor(kmeans_result$cluster))) +
  geom_point(size = 1.0) +  # Adjusted size for smaller points
  geom_point(data = as.data.frame(kmeans_result$centers), aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL), color = "black", size = 3, shape = 4) +  # Adjusted size for cluster centers
  geom_contour(data = grid, aes(z = as.numeric(decision_boundary)), bins = 5, color = "blue", linetype = "dashed") +
  ggtitle("K-means Clustering with Bayes Decision Boundary") +
  scale_color_discrete(name = "Cluster")
```




```{r}
# Load necessary libraries
library(cluster)
library(ggplot2)
library(mclust) # For Gaussian Mixture Model and EM algorithm
library(MASS)   # For Bayes decision boundary
library(gridExtra)

# K-means clustering based on 'Blood_Pressure_mmHg' and 'Cholesterol_mg_dL'
set.seed(123)
kmeans_result <- kmeans(healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], centers = 5)

# Assign cluster to each grid point for the K-means model
x_min <- min(healthcare$Blood_Pressure_mmHg) - 10
x_max <- max(healthcare$Blood_Pressure_mmHg) + 10
y_min <- min(healthcare$Cholesterol_mg_dL) - 10
y_max <- max(healthcare$Cholesterol_mg_dL) + 10

grid <- expand.grid(Blood_Pressure_mmHg = seq(x_min, x_max, length.out = 100),
                    Cholesterol_mg_dL = seq(y_min, y_max, length.out = 100))

assign_cluster <- function(x, centers) {
  distances <- apply(centers, 1, function(center) sqrt(sum((x - center)^2)))
  return(which.min(distances))
}

grid$kmeans_cluster <- apply(grid, 1, assign_cluster, centers = kmeans_result$centers)
grid$kmeans_cluster <- as.factor(grid$kmeans_cluster)

# Fit Gaussian Mixture Model (GMM) without explicit initialization
gmm_result <- Mclust(healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], G = 5)

# Assign cluster to each grid point for the GMM model
grid$gmm_cluster <- predict(gmm_result, newdata = grid[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")])$classification
grid$gmm_cluster <- as.factor(grid$gmm_cluster)

# Estimate Bayes decision boundary using LDA for the GMM clusters
lda_model <- lda(gmm_cluster ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = grid)
grid$decision_boundary <- predict(lda_model, grid)$class

# Plot the results in a two-panel figure

# Upper panel: K-means clustering with piecewise linear decision boundaries
p1 <- ggplot(healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = as.factor(kmeans_result$cluster))) +
  geom_point(size = 3) +
  geom_point(data = as.data.frame(kmeans_result$centers), aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL), color = "black", size = 5, shape = 4) +
  geom_contour(data = grid, aes(z = as.numeric(kmeans_cluster)), bins = 5, color = "blue", linetype = "dashed") +
  ggtitle("K-means Clustering with Piecewise Linear Decision Boundaries") +
  scale_color_discrete(name = "Cluster") +
  theme_minimal()

# Lower panel: GMM clustering with Bayes decision boundary
p2 <- ggplot(healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = as.factor(gmm_result$classification))) +
  geom_point(size = 3) +
  geom_contour(data = grid, aes(z = as.numeric(decision_boundary)), color = "purple", linetype = "dotted") +
  ggtitle("GMM with Common Covariance and Bayes Decision Boundary") +
  scale_color_discrete(name = "Cluster") +
  theme_minimal()

# Combine the plots into a two-panel figure
grid.arrange(p1, p2, ncol = 1)

```


```{r}
# Load necessary libraries
library(cluster)
library(ggplot2)
library(class)  # For k-NN classification
library(MASS)   # For Bayes decision boundary
library(gridExtra)

# K-means clustering (for later comparison)
set.seed(123)
kmeans_result <- kmeans(healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], centers = 5)

# K-NN classification
k <- 5  # Number of neighbors
grid <- expand.grid(Blood_Pressure_mmHg = seq(min(healthcare$Blood_Pressure_mmHg) - 10, max(healthcare$Blood_Pressure_mmHg) + 10, length.out = 100),
                    Cholesterol_mg_dL = seq(min(healthcare$Cholesterol_mg_dL) - 10, max(healthcare$Cholesterol_mg_dL) + 10, length.out = 100))

# Use the k-NN algorithm to classify each point in the grid
knn_result <- knn(train = healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], 
                  test = grid, 
                  cl = kmeans_result$cluster, 
                  k = k)

grid$knn_cluster <- as.factor(knn_result)

# Estimate Bayes decision boundary using LDA for the k-NN clusters
lda_model <- lda(knn_cluster ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = grid)
grid$decision_boundary <- predict(lda_model, grid)$class

# Plot the results in a two-panel figure

# Upper panel: k-NN classification with decision boundaries
p1 <- ggplot() +
  geom_point(data = healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = as.factor(kmeans_result$cluster)), size = 3) +
  geom_contour(data = grid, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, z = as.numeric(knn_cluster)), color = "blue", linetype = "dashed") +
  ggtitle("k-NN Classification with Decision Boundaries") +
  scale_color_discrete(name = "Cluster") +
  theme_minimal()

# Lower panel: Bayes decision boundary overlay
p2 <- ggplot() +
  geom_point(data = healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = as.factor(kmeans_result$cluster)), size = 3) +
  geom_contour(data = grid, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, z = as.numeric(decision_boundary)), color = "purple", linetype = "dotted") +
  ggtitle("Bayes Decision Boundary") +
  scale_color_discrete(name = "Cluster") +
  theme_minimal()

# Combine the plots into a two-panel figure
grid.arrange(p1, p2, ncol = 1)
```

```{r}
# Load necessary libraries
library(cluster)
library(ggplot2)
library(class)  # For k-NN classification
library(caret)  # For cross-validation
library(MASS)   # For Bayes decision boundary
library(gridExtra)

# Assuming 'healthcare' is your dataset and already loaded
# Add a synthetic 'Class' variable for binary classification based on a relevant split
healthcare$Class <- as.factor(ifelse(healthcare$Blood_Pressure_mmHg > median(healthcare$Blood_Pressure_mmHg), 1, 2))

# Function to compute misclassification error for different values of k
calculate_knn_cv_error <- function(k) {
  train_control <- trainControl(method = "cv", number = 10)
  knn_model <- train(Class ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = healthcare, method = "knn",
                     trControl = train_control, tuneGrid = data.frame(.k = k))
  return(knn_model$results)
}

# Evaluate misclassification error for different values of k (1 to 15)
k_values <- 1:15
cv_results <- do.call(rbind, lapply(k_values, calculate_knn_cv_error))

# Upper panel: Plot misclassification error as a function of k
p1 <- ggplot(cv_results, aes(x = k, y = 1 - Accuracy, ymin = 1 - (Accuracy + AccuracySD), ymax = 1 - (Accuracy - AccuracySD))) +
  geom_errorbar(width = 0.2) +
  geom_line() +
  geom_point() +
  labs(title = "Misclassification Error as a Function of k",
       x = "Number of Neighbors (k)",
       y = "Misclassification Error") +
  theme_minimal()

# Lower panel: Decision boundary for k=7 with Bayes decision boundary
k_optimal <- 7
grid <- expand.grid(Blood_Pressure_mmHg = seq(min(healthcare$Blood_Pressure_mmHg) - 10, max(healthcare$Blood_Pressure_mmHg) + 10, length.out = 100),
                    Cholesterol_mg_dL = seq(min(healthcare$Cholesterol_mg_dL) - 10, max(healthcare$Cholesterol_mg_dL) + 10, length.out = 100))

knn_result <- knn(train = healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], 
                  test = grid, 
                  cl = healthcare$Class, 
                  k = k_optimal)

grid$knn_cluster <- as.factor(knn_result)

# Estimate Bayes decision boundary using LDA
lda_model <- lda(Class ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = healthcare)
grid$decision_boundary <- predict(lda_model, grid)$class

# Lower panel: Plot decision boundary for k=7
p2 <- ggplot() +
  geom_point(data = healthcare, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, color = Class), size = 3) +
  geom_contour(data = grid, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, z = as.numeric(knn_cluster)), color = "blue", linetype = "dashed") +
  geom_contour(data = grid, aes(x = Blood_Pressure_mmHg, y = Cholesterol_mg_dL, z = as.numeric(decision_boundary)), color = "purple", linetype = "dotted") +
  ggtitle("Decision Boundary for k = 7 with Bayes Decision Boundary") +
  scale_color_discrete(name = "Class") +
  theme_minimal()

# Combine the plots into a two-panel figure
grid.arrange(p1, p2, ncol = 1)
```


```{r}
# Load necessary libraries
library(cluster)
library(ggplot2)
library(class)  # For k-NN classification
library(caret)  # For cross-validation and LVQ
library(MASS)   # For Bayes decision boundary
library(purrr)  # For map functions

# Assuming 'healthcare' is your dataset and already loaded
# Add a synthetic 'Class' variable for binary classification based on a relevant split
healthcare$Class <- as.factor(ifelse(healthcare$Blood_Pressure_mmHg > median(healthcare$Blood_Pressure_mmHg), 1, 2))

# Function to compute misclassification error for k-NN, K-means, and LVQ
calculate_errors <- function(data) {
  set.seed(123)
  
  # k-NN
  train_control <- trainControl(method = "cv", number = 10)
  knn_model <- train(Class ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = data, method = "knn",
                     trControl = train_control, tuneGrid = data.frame(.k = 7))
  knn_error <- 1 - max(knn_model$results$Accuracy)
  
  # K-means
  kmeans_result <- kmeans(data[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], centers = 2)
  kmeans_pred <- as.factor(ifelse(kmeans_result$cluster == 1, "1", "2"))
  kmeans_error <- mean(kmeans_pred != data$Class)
  
  # LVQ using caret
  lvq_model <- train(Class ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = data, method = "lvq",
                     trControl = train_control)
  lvq_error <- 1 - max(lvq_model$results$Accuracy)
  
  return(c(knn_error, kmeans_error, lvq_error))
}

# Perform 10 realizations for the dataset
errors_realizations <- replicate(10, calculate_errors(healthcare))

# Calculate Mean ± Standard Error for each method
error_stats <- function(errors) {
  mean_errors <- rowMeans(errors)
  se_errors <- apply(errors, 1, sd) / sqrt(ncol(errors))
  return(data.frame(
    Method = c("k-NN", "K-means", "LVQ"),
    Mean = mean_errors,
    SE = se_errors
  ))
}

error_stats_combined <- error_stats(errors_realizations)

# Plot the results
ggplot(error_stats_combined, aes(x = Method, y = Mean, fill = Method)) +
  geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +
  geom_errorbar(aes(ymin = Mean - SE, ymax = Mean + SE), position = position_dodge(0.7), width = 0.25) +
  labs(title = "Mean ± One Standard Error of Misclassification Error",
       y = "Misclassification Error",
       x = "Method") +
  scale_fill_manual(values = c("k-NN" = "green", "K-means" = "blue", "LVQ" = "red")) +
  theme_minimal()
```


```{r}
# Load necessary libraries
library(cluster)
library(ggplot2)
library(class)  # For k-NN classification
library(caret)  # For LVQ and K-means through training
library(MASS)
library(gridExtra)

# Assuming 'healthcare' is your dataset and already loaded
# Add a synthetic 'Class' variable for binary classification based on a relevant split
healthcare$Class <- as.factor(ifelse(healthcare$Blood_Pressure_mmHg > median(healthcare$Blood_Pressure_mmHg), 1, 2))

# Function to calculate k-NN misclassification errors
calculate_knn_errors <- function(data, k_values) {
  errors <- sapply(k_values, function(k) {
    knn_model <- train(Class ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = data, method = "knn",
                       trControl = trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(.k = k))
    return(1 - max(knn_model$results$Accuracy))
  })
  return(errors)
}

# Function to calculate K-means misclassification errors
calculate_kmeans_errors <- function(data, proto_values) {
  errors <- sapply(proto_values, function(proto) {
    kmeans_result <- kmeans(data[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL")], centers = proto)
    cluster_assignment <- as.factor(ifelse(kmeans_result$cluster == 1, "1", "2"))
    return(mean(cluster_assignment != data$Class))
  })
  return(errors)
}

# Function to calculate LVQ misclassification errors
calculate_lvq_errors <- function(data, proto_values) {
  errors <- sapply(proto_values, function(proto) {
    lvq_model <- train(Class ~ Blood_Pressure_mmHg + Cholesterol_mg_dL, data = data, method = "lvq",
                       trControl = trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(size = proto, k = 5))
    return(1 - max(lvq_model$results$Accuracy))
  })
  return(errors)
}

# Define the values to test
k_values <- seq(1, 60, by = 5)
proto_values <- seq(5, 30, by = 5)

# Calculate errors for the healthcare dataset
knn_errors <- calculate_knn_errors(healthcare, k_values)
kmeans_errors <- calculate_kmeans_errors(healthcare, proto_values)
lvq_errors <- calculate_lvq_errors(healthcare, proto_values)

# Create plots
p1 <- ggplot(data.frame(k_values, knn_errors), aes(x = k_values, y = knn_errors)) +
  geom_line(color = "blue") +
  geom_point(color = "blue") +
  ggtitle("Nearest Neighbors") +
  xlab("Number of Neighbors") +
  ylab("Misclassification Error") +
  ylim(0, 0.6) +
  theme_minimal()

p2 <- ggplot(data.frame(proto_values, kmeans_errors, lvq_errors), aes(x = proto_values)) +
  geom_line(aes(y = kmeans_errors), color = "blue") +
  geom_point(aes(y = kmeans_errors), color = "blue") +
  geom_line(aes(y = lvq_errors), color = "red") +
  geom_point(aes(y = lvq_errors), color = "red") +
  ggtitle("K-means & LVQ") +
  xlab("Number of Prototypes per Class") +
  ylab("Misclassification Error") +
  ylim(0, 0.6) +
  theme_minimal()

# Arrange the plots in a 1x2 grid
grid.arrange(p1, p2, ncol = 2)
```


```{r}
# Load necessary libraries
library(class)
library(ggplot2)
library(tidyr)
library(gridExtra)

# Assuming 'healthcare' is already loaded and contains the relevant columns
# Select relevant columns for k-NN
data <- healthcare[, c("Blood_Pressure_mmHg", "Cholesterol_mg_dL", "BMI", "Dosage_Med1_mg")]

# Check if the columns are numeric and convert if necessary
data <- data.frame(lapply(data, function(x) as.numeric(as.character(x))))

# Handle missing values by imputing with the column mean
data <- data.frame(lapply(data, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x)))

# Create a synthetic 'LandUsage' class for demonstration (since your dataset might not have one)
data$LandUsage <- factor(ifelse(data$Blood_Pressure_mmHg > median(data$Blood_Pressure_mmHg), 1, 2))

# Apply k-NN classification
predicted_land_usage <- knn(train = data[, 1:4], test = data[, 1:4], cl = data$LandUsage, k = 5)

# Helper function to convert a matrix to a data frame suitable for ggplot
matrix_to_df <- function(mat, name) {
  df <- as.data.frame(mat)
  df$row <- 1:nrow(df)
  df <- pivot_longer(df, cols = -row, names_to = "col", values_to = name)
  df$col <- as.integer(gsub("V", "", df$col))
  return(df)
}

# Convert the actual and predicted land usage into matrices for plotting
n <- sqrt(nrow(data))  # Calculate the grid size
df_actual <- matrix_to_df(matrix(as.numeric(data$LandUsage), nrow = n), "value")
df_predicted <- matrix_to_df(matrix(as.numeric(predicted_land_usage), nrow = n), "value")

# Plot actual land usage
p5 <- ggplot(df_actual, aes(x = col, y = row, fill = as.factor(value))) +
  geom_tile() +
  scale_fill_manual(values = c("#FF0000", "#00FF00")) +
  ggtitle("Actual Land Usage") +
  theme_minimal() +
  theme(axis.text = element_blank(), axis.title = element_blank())

# Plot predicted land usage
p6 <- ggplot(df_predicted, aes(x = col, y = row, fill = as.factor(value))) +
  geom_tile() +
  scale_fill_manual(values = c("#FF0000", "#00FF00")) +
  ggtitle("Predicted Land Usage (5-NN)") +
  theme_minimal() +
  theme(axis.text = element_blank(), axis.title = element_blank())

# Arrange the plots side by side
grid.arrange(p5, p6, ncol = 2)


```
